{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_Yelp2014.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "DZwPLH5QB-wJ",
        "colab_type": "code",
        "outputId": "a1f55d2b-bc8a-4cb0-8701-28fb325b935a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VXN2WXKpCKjd",
        "colab_type": "code",
        "outputId": "2136b2f7-c02b-4f78-b2d8-fb99cc3713c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "cd /content/drive/My\\ Drive/Colab\\ Notebooks/dataset"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CK4NNM-QCpxc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ]
    },
    {
      "metadata": {
        "id": "-u7X08UDCob8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('yelp2014.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e2EaTTtpldpM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "msk = np.random.rand(len(data)) < 0.9\n",
        "train = data[msk]\n",
        "test = data[~msk]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "flIJu7qjQosV",
        "colab_type": "code",
        "outputId": "73a5e8c1-196c-4168-97cc-9d698c66ff60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "Y_train = train['stars'][:].values\n",
        "X_train = train['text'][:].values\n",
        "Y_test = test['stars'][:].values\n",
        "X_test = test['text'][:].values\n",
        "X_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1012527,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "vR1e7QilQe6r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Split into train/validation sets"
      ]
    },
    {
      "metadata": {
        "id": "upNHWRaQIZc2",
        "colab_type": "code",
        "outputId": "78f49b91-864f-4049-dc48-94786eefa9d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "random_seed = 2\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)\n",
        "X_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(911274,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "qmT1Lk4AgnBM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del data\n",
        "del train\n",
        "del test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tw2Q8i1sVv-I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SVM"
      ]
    },
    {
      "metadata": {
        "id": "C4RwKsN6Vu7w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lsvm = Pipeline([\n",
        "    ('vect', CountVectorizer(ngram_range=(1,1))),\n",
        "    ('norm', Normalizer()),\n",
        "    ('clf', LinearSVC(random_state = 0, tol = 1e-7)),\n",
        "])\n",
        "\n",
        "lsvm.fit(X_train, Y_train)\n",
        "y_pred = lsvm.predict(X_test)\n",
        "print('SVM-unigram Accuracy', accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G0KhjPLepBoC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lsvm2 = Pipeline([\n",
        "    ('vect', CountVectorizer(ngram_range=(2,2))),\n",
        "    ('norm', Normalizer()),\n",
        "    ('clf', LinearSVC(random_state = 0, tol = 1e-7)),\n",
        "])\n",
        "\n",
        "lsvm2.fit(X_train, Y_train)\n",
        "y_pred = lsvm2.predict(X_test)\n",
        "print('SVM-bigram Accuracy', accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Nm_MAkTtLgk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lsvm3 = Pipeline([\n",
        "    ('vect', CountVectorizer(ngram_range=(1,2))),\n",
        "    ('norm', Normalizer()),\n",
        "    ('clf', LinearSVC(random_state = 0, tol = 1e-7)),\n",
        "])\n",
        "\n",
        "lsvm3.fit(X_train, Y_train)\n",
        "y_pred = lsvm3.predict(X_test)\n",
        "print('SVM-[uni,bi]gram Accuracy', accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jQML1pWDxUKW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lsvm4 = Pipeline([\n",
        "    ('vect', CountVectorizer(ngram_range=(1,3))),\n",
        "    ('norm', Normalizer()),\n",
        "    ('clf', LinearSVC(random_state = 0, tol = 1e-7)),\n",
        "])\n",
        "\n",
        "lsvm4.fit(X_train, Y_train)\n",
        "y_pred = lsvm4.predict(X_test)\n",
        "print('SVM-[uni,bi,tri]gram Accuracy', accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-7NdtQydUHGn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lsvm5 = Pipeline([\n",
        "    ('vect', CountVectorizer(ngram_range=(3,3))),\n",
        "    ('norm', Normalizer()),\n",
        "    ('clf', LinearSVC(random_state = 0, tol = 1e-7)),\n",
        "])\n",
        "\n",
        "lsvm5.fit(X_train, Y_train)\n",
        "y_pred = lsvm5.predict(X_test)\n",
        "print('SVM-trigram Accuracy', accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8280-RpxZJg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lsvm6 = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('norm', Normalizer()),\n",
        "    ('clf', LinearSVC(random_state = 0, tol = 1e-7)),\n",
        "])\n",
        "\n",
        "lsvm6.fit(X_train, Y_train)\n",
        "y_pred = lsvm6.predict(X_test)\n",
        "print('TF-IDF Accuracy', accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gtubag4oFeeV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Multinomial Naive Bayes"
      ]
    },
    {
      "metadata": {
        "id": "pmkvKyNDFdsx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnb = Pipeline([\n",
        "    ('vect', CountVectorizer(ngram_range=(1,2))),\n",
        "    ('norm', Normalizer()),\n",
        "    ('clf', MultinomialNB(alpha=0.01)),\n",
        "])\n",
        "\n",
        "mnb.fit(X_train, Y_train)\n",
        "y_pred = mnb.predict(X_test)\n",
        "print('Multinomial NB Accuracy', accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JAH0PqRQxbIj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "mZcG2y_nxci1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('yelp2014.csv')\n",
        "msk = np.random.rand(len(data)) < 0.9\n",
        "train = data[msk]\n",
        "test = data[~msk]\n",
        "\n",
        "Y_train = train['stars']\n",
        "X_train = train['text']\n",
        "Y_test = test['stars']\n",
        "X_test = test['text']\n",
        "X_train.shape\n",
        "\n",
        "del train\n",
        "del test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8EkbbL7uxt_2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "lm = WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EMdzd1-Kxmq9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(dataset):\n",
        "    dataset.apply(lambda x: \" \".join(x.lower() for x in x.split()))               # lowercase\n",
        "    dataset.str.replace('[^\\w\\s]','')                                             # remove punctuations\n",
        "    dataset.apply(lambda x: \" \".join(x for x in x.split() if x not in stop))      # remove stopwords\n",
        "    dataset.apply(lambda x: \" \".join([lm.lemmatize(word) for word in x.split()])) # lemmatization\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yLRaDiw-xzyr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = preprocess(X_train)\n",
        "X_test = preprocess(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bM3Eqxu87pGY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "metadata": {
        "id": "i_2bKoBex-Ds",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Most frequent words"
      ]
    },
    {
      "metadata": {
        "id": "7tVBwU1Yx9Gp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "freq = pd.Series(' '.join(X_train).split()).value_counts()\n",
        "freq[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "don5ur4nyBLP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Least frequent words"
      ]
    },
    {
      "metadata": {
        "id": "GfFfogTjx4Kn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "freq[-10:]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}