{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logreg.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "j6KoSFJFcrys",
        "colab_type": "code",
        "outputId": "94f0993b-023e-4119-d58e-2a6fbbb87d50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "#import matplotlib.image as img\n",
        "#import seaborn as sns\n",
        "#import pickle\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#import itertools\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "from sklearn import datasets\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t4AzWzBu4Y4c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# cd /content/drive/My\\ Drive/Colab\\ Notebooks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YJBUyTR9gKVQ",
        "colab_type": "code",
        "outputId": "45ce333e-9675-4059-c679-bfea91c3d731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd /content/drive/My\\ Drive/Colab\\ Notebooks/dataset/input"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/dataset/input\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m5l7zn5hd2Ts",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ]
    },
    {
      "metadata": {
        "id": "DQvDzffWd3sc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test = pd.read_csv('./test_yelp.csv')\n",
        "data = pd.read_csv('./yelp2013.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7pldg6zeh_C3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "msk = np.random.rand(len(data)) < 0.9\n",
        "train = data[msk]\n",
        "test = data[~msk]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d9EOYK4qkpCI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocess"
      ]
    },
    {
      "metadata": {
        "id": "TeINjO6Smc02",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "cb220546-145e-41be-9476-4fefcafb690a"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lm = WordNetLemmatizer()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LLYqrbJXeDdI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(dataset):\n",
        "    dataset.apply(lambda x:\" \".join(x.lower() for x in x.split()))\n",
        "    dataset.str.replace('[^\\w\\s]','')\n",
        "    dataset.apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "    dataset.apply(lambda x: \" \".join([lm.lemmatize(word) for word in x.split()]))\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gBSEUXCDmt6u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Split"
      ]
    },
    {
      "metadata": {
        "id": "5pXLkQlWdEbC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_train = train['stars']\n",
        "X_train = train['text']\n",
        "Y_test = test['stars']\n",
        "X_test = test['text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DEthqGPXmwSy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = preprocess(X_train)\n",
        "X_test = preprocess(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_yMlYmSllQWo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "random_seed = 2\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LQhUsojmksfM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Delete data"
      ]
    },
    {
      "metadata": {
        "id": "3kCMo9_4lSEF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del data\n",
        "del train\n",
        "del test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qR6S8zFzhmZb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "OT7W_6BIhjGP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logreg = Pipeline([\n",
        "    ('vect', CountVectorizer(binary = True)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('norm', Normalizer()),\n",
        "    ('clf', LogisticRegression(C=10)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DHZR_eJShxr7",
        "colab_type": "code",
        "outputId": "e1a0ec7c-ad81-4f8a-da99-229af020640e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "cell_type": "code",
      "source": [
        "seed = 130\n",
        "start = time.time()\n",
        "params_log = {\"vect__ngram_range\": [(1,1),(1,2),(2,2)],\n",
        "              \"vect__binary\":[True, False],\n",
        "              \"vect__max_features\":[50000,100000],\n",
        "              \"clf__penalty\": [\"l2\"]}\n",
        "logreg_cv = GridSearchCV(logreg, param_grid = params_log, cv=2, verbose = 10, n_jobs = -1)\n",
        "logreg_cv.fit(X_train, Y_train)\n",
        "end = time.time()\n",
        "running_time = end-start\n",
        "print(\"Running time is \",running_time)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  3.4min\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  9.7min\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 23.0min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 31.3min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 54.9min\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed: 59.2min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed: 59.2min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running time is  4325.974917888641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vnYRAlyWi_js",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = logreg_cv.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iFknuVJsjFdg",
        "colab_type": "code",
        "outputId": "908c00ff-4876-48fa-ef86-a4cd8c3a4939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(Y_test, y_pred)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6921380461345891"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}